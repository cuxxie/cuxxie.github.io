<!DOCTYPE html>

<meta charset="UTF-8">
<title>WebCodecs API demo: Encoding and Decoding</title>
<style>
  button {
    background-color: #555555;
    border: 2px;
    border-radius: 2px;
    color: white;
    padding: 15px 32px;
    width: 1280px;
    text-align: center;
    display: block;
    font-size: 16px;
  }
</style>

<button id="record" width=1280 onclick="onButtonClicked()">Record</button>
<video id="src" autoplay muted width=1280 height=720></video>
<script>
  let video = document.getElementById('src');
  let button = document.getElementById('record');
  let encodeWorker = null;
  let stream = null;
  let videoTrack = null;
  let map = new Map();
  let duration = [];
  
  async function startRecording() {
    console.assert(button.innerText == 'Record');
    button.disabled = true;

    handle = await window.showSaveFilePicker({
      startIn: 'videos',
      suggestedName: 'myVideo.webm',
      types: [{
        description: 'Video File',
        accept: { 'video/webm': ['.webm'] }
      }],
    });

    // In your startRecording function or a similar setup
    let currentTimestamp = 0;
    const frameRate = 30; // Desired frames per second
    const frameDuration = 1000000 / frameRate; // Duration in microseconds

    const frameStream = new ReadableStream({
      async pull(controller) {
        // Or use setInterval/requestAnimationFrame for continuous generation
        // For this pull-based example, we generate a frame when requested
        const blackFrame = createBlackI420Frame(1280, 720, currentTimestamp);
        controller.enqueue(blackFrame);
        currentTimestamp += frameDuration;

        // Add logic to stop the stream or handle backpressure if needed
      }
    });

    const trackSettings = {
      width: 1280,
      height: 720,
      frameRate: 30 // Match your generation rate
      // Add other relevant settings if your worker expects them
    };

    // videoTrack = stream.getTracks()[0];
    // let trackSettings = videoTrack.getSettings();
    // let trackProcessor = new MediaStreamTrackProcessor(videoTrack);
    // let frameStream = trackProcessor.readable;

    // Encoder I/O and file writing happens in a Worker to keep the UI
    // responsive.
    encodeWorker = new Worker('./encode-worker.js');

    // Tell the worker to start encoding the frames and writing the file.
    // NOTE: transferring frameStream and reading it in the worker is more
    // efficient than reading frameStream here and transferring VideoFrames
    // individually. This allows us to entirely avoid processing frames on the
    // main (UI) thread.
    encodeWorker.postMessage({
      type: 'start',
      fileHandle: handle,
      frameStream: frameStream,
      trackSettings: trackSettings
    }, [frameStream]);

    button.innerText = 'Stop';
    button.disabled = false;
  }

  function stopRecording() {
    console.assert(button.innerText == 'Stop');
    button.innerText = 'Record';
    encodeWorker.postMessage({ type: 'stop' });
    return;
  }

  async function onButtonClicked() {
    switch (button.innerText) {
      case 'Record':
        startRecording();
        break;
      case 'Stop':
        stopRecording();
        break;
    }
  };

  // Example for generating a black I420 frame
  function createBlackI420Frame(width, height, timestamp) {
    const yPlaneSize = width * height;
    const uvPlaneSize = (width / 2) * (height / 2);
    const frameDataSize = yPlaneSize + 2 * uvPlaneSize;
    const frameBuffer = new ArrayBuffer(frameDataSize);
    const frameData = new Uint8Array(frameBuffer);

    // Fill Y plane with 0 (black)
    frameData.fill(0, 0, yPlaneSize);
    // Fill U and V planes with 128 (neutral chroma)
    frameData.fill(128, yPlaneSize, yPlaneSize + 2 * uvPlaneSize);

    return new VideoFrame(frameData, {
      format: 'I420',
      codedWidth: width,
      codedHeight: height,
      timestamp: timestamp, // in microseconds
      // You might need to specify layout for planar formats if default isn't I420
      // layout: [
      //   { offset: 0, stride: width }, // Y
      //   { offset: yPlaneSize, stride: width / 2 }, // U
      //   { offset: yPlaneSize + uvPlaneSize, stride: width / 2 }  // V
      // ]
      // colorSpace can also be specified if needed
    });
  }

  async function main() {
    // let constraints = {
    //   audio: false,
    //   video: {width: 1280, height: 720, frameRate: 30}
    // };
    // stream = await window.navigator.mediaDevices.getUserMedia(constraints);
    // let video = document.getElementById('src');
    // video.srcObject = stream;


    // In your startRecording function or a similar setup
  }

  document.body.onload = main;
</script>